This is the README file for A0116733J-A0115696W's submission

== General Notes about this assignment ==

your system architecture and how your system deals with each of the optional components (query expansion, utilizing external resources, field/zone treatment, run-time optimizations,

<<<Mini Patent Retrieval System Architecture Overview>>>

As known, there are two main components in the system: Indexing and Searching.

In pre-processing, the Indexing component does the following:
1. Use xml.etree.ElementTree to parse patsnap corpus XML files.
2. Index only Title and Abstract of the patent files
3. Use Porter Stemmer and Stopword list filtering for text processing
4. Use Gensim library to implement topic modeling

When user query the system, the Searching component does the following:
1. Dissect query into a bag of words
2. Use tf-idf weighting with query terms
3. Model the query with Latent Semantic Indexing 
4. Compare query with LSI models (???)





Our query system consists of the following components:

1) Breakdown of query into a vector space (bag-of-words model)
2) Weighted the words in the query via TF-IDF
3) Modeled the query with Latent Semantic Indexing (http://en.wikipedia.org/wiki/Latent_semantic_indexing)
4) Ran the query against the LSI space of the indexed, LSI-modeled, TF-IDF weighted corpus

For this assignment, we utilized an external resource (GenSim) to assist us in the topic modeling of the query, as well as the TF-IDF weighted corpus.

Main Points Of The Query System:

I) Uses Python library xml.etree.ElementTree to parse the XML files. Data parsed will have a tree data structure.

II) Indexed the <abstract> and <title> of the patent files.

III) Implemented NLTK library to implement lemmatisation, stemming and removal of stopwords.

IV) Utilized GenSim library for topic modeling, TF-IDF weighting and converting query into a bag-of-words model.

V) Query XML file utilized both <title> and <description> for the query's bag-of-words model. Used the bag-of-words model to conduct similarity query against the corpus.

VI) In addition, the query utilized TF-IDF and LSI using topic modelling via GenSim. The number of topics, to determine the number of latent dimensions for modeling, we eventually decided on was 50. This was due to our findings (http://stackoverflow.com/questions/9582291/how-do-we-decide-the-number-of-dimensions-for-latent-semantic-analysis) which mentioned the use of 400 on millions of documents, 300 on hundreds of thousands of documents, and we subsequently scaled back the dimensions accordingly to derive 50.

VII) The intuition behind our method was to utilize the top 25 relevant documents (which is approximately 1% of the total corpus size). From the top 1% of documents, we found the most frequent IPC subclass that appeared within this list, and retrieved all the documents from the corpus that had this IPC subclass. The final list was generated by combining the retrieved documents of that subclass AND the top 25 relevant documents. 

Justiication: 

From the most frequent subclass that occurs within the top 1% of documents, we extrapolated our reasoning to believe that the majority of the results that would be relevant would be from that same subclass (Since most of the top relevant documents came from the said subclass). In addition, the IPC classification system has already grouped the patents into some form of relevant categories, which fueled our reasoning that there would be less relevant documents in the other subclasses (though NOT impossible).

Our aim was not to retrieve every single relevant document, but to retrieve the majority of the relevant documents with the greatest likelihood, without actually returning too many irrelevant documents.


---- Field/Zone Treatment ----
For this particular assignment, we indexed the words inside the <abstract> and <title> fields of the patent files. 

Main Points Of The Field/Zone Treatment:

I) Indexed the IPC subclass and the documents pertaining to that subclass in seperate a file, "IPCtoDoc.txt"

II) Used this mapping in this file to retrieve documents from the most frequently occuring subclass, within the top 1% of documents.

III) We attempted to use the zones and fields by integrating it with the words, e.g. wash.title, wash.abstract, but decided ultimately to remove it in the end as we did not see much improvement in our results.
 

---- Things that we tried but removed in the final build ----

Main Points For Previous Attempts:

I) We attempted the use of the Latent Dirichlet Allocation model, but the performance results fared worse-off as compared to the use of Latent Semantic Indexing. As a result, we decided against it and chose to use Latent Semantic Indexing instead.

II) We attempted query expansion, by indexing all the words in title and abstract from the top 1% of the results, but it did not work very well possibly due to the extra noise produced by the additional words in the patents. May work better if we are able to determine the key words, instead of indexing all the words in the patent files.

III) Our code for other previous attempts can be found in our index.py and search.py files (Commented out)

---- Allocation of Work ----
I) Choo Jia Le: Did research on Latent Semantic Indexing heuristics, testing of cases and brainstorming on further ideas to improve precision and accuracy.

II) Lim Jing Rong: Did debugging, testing of cases and research of Latent Dirichlet Allocation modeling heuristics.

III) Nelson Goh: Did research on the ideas of topic modeling and implementation on Python. Found relevant libraries and models to use for this assignment.

All members participated and contributed equally and carried out pair-programming during the period of this assignment.


---- Misc -----
We also created a function (is_ascii) to detect non-ascii characters during the reading of our patent documents, and subsequently ignore it, as part of processing.

Things that we could have done better:

I) Could have carried out more queries and conducted more experiements to find out a more accurate distribution of topics for our corpus, for better modeling.
 
== Files included with this submission ==

List the files in your submission here and provide a short 1 line
description of each file.  Make sure your submission's files are named
and formatted correctly.

-gensim					// Third-party library that does topic modelling 
-dictionary.txt 		// Dictionary object from gensim written to this file 
-filenames.txt 			// (Not included in submission, appears only when running index.py) This is a list of the patent names in the patsnap-corpus
-index.py 				// The file that indexes patsnap-corpus. Generates dictionary.txt and postings.txt
-ipc_subclass.txt 		// ??????
-postings.txt 			// Matrix from gensim written to this file
-README.md 				// self-explanatory
-search.py 				// The file that returns a ranked results based of xml search query


== Statement of individual work ==

Please initial one of the following statements.

[X] I, A0116733J, certify that my partners (A0115696W) and I have followed the CS 3245 Information
Retrieval class guidelines for homework assignments.  In particular, I
expressly vow that I have followed the Facebook rule in discussing
with others in doing the assignment and did not take notes (digital or
printed) from the discussions.  

[X] I, A0116733J-A0115696W, did not follow the class rules regarding homework
assignment, because of the following reason:

// text

I suggest that I should be graded as follows:

// text

== References ==

Discussed with Nelson, who has previously taken this module.